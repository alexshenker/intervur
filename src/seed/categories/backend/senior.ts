import { Category, Level, ValidTag } from "../../../db/constants";
import type { QuestionForCategoryAndLevel } from "../../../lib/types";

export const senior: QuestionForCategoryAndLevel<
    typeof Category.enum.backend,
    typeof Level.enum.senior
>[] = [
    {
        text: "What are race conditions and how do you handle them?",
        level: Level.enum.senior,
        category: Category.enum.backend,
        tags: [ValidTag.enum["race-conditions"], ValidTag.enum.concurrency],
        answers: [
            "A race condition occurs when the behavior of code depends on the timing or interleaving of multiple concurrent operations. The classic example is two processes trying to update the same bank account balance at the same time. If both read the balance as one hundred dollars, then both add fifty dollars and write back one hundred fifty, you've lost fifty dollars instead of having two hundred. I handle race conditions differently depending on the context. At the database level, I use transactions with appropriate isolation levels. For critical operations like financial transactions, I might use serializable isolation or SELECT FOR UPDATE to lock rows. For counters and simple updates, atomic operations like PostgreSQL's UPDATE with expressions or Redis's INCR avoid read-modify-write races entirely. At the application level, I use mutexes or locks for shared resources in multi-threaded code. In distributed systems, I might use distributed locks with Redis or a coordination service like ZooKeeper, though I try to avoid this when possible by designing for idempotency instead. Optimistic concurrency control is another approach I use frequently. You add a version number or timestamp to records and check it hasn't changed before committing updates. If it has, you retry or fail gracefully. The key is identifying where races can occur during design, not after they've caused production incidents.",
            "Race conditions happen when correctness depends on timing of concurrent operations. The danger: non-deterministic bugs that appear randomly and are hard to reproduce. Classic pattern: read-modify-write. Two threads read a value, both modify it, both write back. One update is lost. Solutions depend on context. Database level: atomic updates - UPDATE balance = balance + 50 instead of reading then writing. SELECT FOR UPDATE locks rows during a transaction. Proper isolation levels prevent phantom reads. For high contention, consider SERIALIZABLE isolation. Application level: use atomic operations where available. Redis INCR, database sequences. These avoid races entirely. When you must lock, use mutexes for single-process or distributed locks for multi-node. Be careful of deadlocks - always acquire locks in consistent order. Optimistic concurrency: add a version column. Read version with data, include version in WHERE clause on update. If version changed, someone else modified it - retry or fail. Design patterns: idempotent operations are naturally safe to retry. Event sourcing with append-only logs avoids update races. CQRS separates reads from writes, reducing contention. Prevention is key - identify race-prone code during design reviews."
        ],
    },
    {
        text: "When would you choose one microservices communication protocol over another?",
        level: Level.enum.senior,
        category: Category.enum.backend,
        tags: [ValidTag.enum.microservices],
        answers: [
            "The choice of communication protocol depends on the specific requirements of the interaction. For synchronous request-response patterns where a service needs an immediate answer, REST over HTTP is my default choice. It's simple, well-understood, and has great tooling. The APIs are easy to debug with curl or Postman, and it works well for CRUD operations. When I need better performance or have complex data structures, I consider gRPC. It uses Protocol Buffers for efficient binary serialization, supports streaming, and generates type-safe client libraries. It's particularly good for internal service-to-service communication where the human readability of REST isn't as important. For asynchronous communication where I want to decouple services, I use message queues like RabbitMQ or Kafka. This is ideal for event-driven architectures where a service publishes events and multiple consumers can react independently. It also gives you natural resilience since messages persist in the queue if a consumer is temporarily down. If I need real-time bidirectional communication, WebSockets or Server-Sent Events come into play. GraphQL is another option when the client needs flexibility in what data it fetches, though I typically use it at the edge between frontend and a backend-for-frontend service rather than between microservices. The key is matching the protocol to the communication pattern rather than using one approach for everything.",
            "I choose based on communication pattern and requirements. Synchronous request-response: REST for simplicity, broad tooling, and debuggability. Every developer knows it, curl works, it's cacheable. gRPC when performance matters - binary Protocol Buffers are faster and smaller, HTTP/2 multiplexing is efficient, generated clients ensure type safety. Great for internal high-throughput service calls. Asynchronous events: message brokers like Kafka or RabbitMQ. Services publish events, consumers process independently. This decouples services temporally - producer doesn't wait for consumer. Enables event sourcing, saga patterns, and resilience when consumers are down. Kafka for high throughput and replay. RabbitMQ for flexible routing. Streaming: gRPC bidirectional streaming for continuous data flow. Server-Sent Events for simpler server-to-client push. WebSockets when you need full duplex. Hybrid approaches: API Gateway handles external REST/GraphQL, internal services use gRPC for performance. Events via message broker for cross-domain communication. The mistake is choosing one protocol for everything. Match the tool to the interaction pattern. Synchronous queries need request-response. Fire-and-forget notifications need async messaging. Real-time updates need streaming."
        ],
    },
];
