import { Category, Level, ValidTag } from "../../../db";
import type { QuestionForCategoryAndLevel } from "../../../lib/types";

export const mid: QuestionForCategoryAndLevel<
    typeof Category.enum.frontend,
    typeof Level.enum.mid
>[] = [
    // JavaScript
    {
        text: "What is the event loop and how does it handle asynchronous operations?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.javascript, ValidTag.enum["event-loop"], ValidTag.enum["async-await"]],
        answers: ["The event loop is JavaScript's mechanism for handling asynchronous operations in a single-threaded environment. It continuously monitors the call stack and task queues. When the call stack is empty, it takes the first task from the queue and pushes it onto the stack for execution. Async operations like setTimeout or API calls are handled by browser APIs or Node.js APIs outside the main thread. When they complete, their callbacks are placed in either the microtask queue for Promises or the macrotask queue for things like setTimeout. Microtasks always run before macrotasks, which is why Promise callbacks execute before setTimeout callbacks even if they're scheduled at the same time."],
    },
    {
        text: "What are Promises and how do they differ from async/await?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.javascript, ValidTag.enum.promises, ValidTag.enum["async-await"]],
        answers: ["Promises are objects representing the eventual completion or failure of an asynchronous operation. They have three states: pending, fulfilled, or rejected, and you chain operations using .then() and .catch(). Async/await is syntactic sugar built on top of Promises that makes asynchronous code look more synchronous and easier to read. The key difference is readability and error handling - with async/await you can use try/catch blocks instead of chaining .catch(), and the code flows more naturally. However, they're fundamentally the same under the hood. One thing to note is that async/await makes sequential operations easier to write, but you need to be careful not to serialize operations that could run in parallel - for that, you'd still use Promise.all()."],
    },
    {
        text: "What is event delegation and why is it useful?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.javascript],
        answers: ["Event delegation is a technique where you attach a single event listener to a parent element instead of multiple listeners to individual child elements. It works because of event bubbling - when an event occurs on a child element, it bubbles up through its ancestors. You can check event.target to see which specific element triggered the event. This is really useful for performance when you have many similar elements like list items or table rows, since you only need one listener instead of hundreds. It also handles dynamically added elements automatically without needing to attach new listeners. I use this pattern frequently when building things like todo lists or data tables where items are added and removed dynamically."],
    },
    {
        text: "What are generators and iterators?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.javascript, ValidTag.enum.generators, ValidTag.enum.iterators],
        answers: ["Iterators are objects that implement the iterator protocol by having a next() method that returns an object with 'value' and 'done' properties. They let you define custom iteration behavior for objects. Generators are special functions defined with function* that can pause and resume execution using the yield keyword. When you call a generator function, it returns a generator object which is also an iterator. Generators make it much easier to create iterators without manually implementing the iterator protocol. They're useful for lazy evaluation, like generating infinite sequences, or for managing complex async flows. Redux-Saga, for example, uses generators heavily for side effect management. Though honestly, in modern applications, you see async/await more often than generators for async operations."],
    },
    {
        text: "What are Web Workers and when would you use them?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.javascript, ValidTag.enum.performance],
        answers: ["Web Workers are JavaScript scripts that run in background threads separate from the main browser thread. They let you perform heavy computations without blocking the UI. You communicate with workers through message passing using postMessage and onmessage. I'd use them for CPU-intensive tasks like image processing, large data parsing, complex calculations, or cryptographic operations. The main limitation is that workers don't have access to the DOM - they run in a completely separate context. A common use case would be processing a large CSV file or performing real-time data analysis without freezing the interface. However, there's overhead in setting them up and transferring data, so for quick operations they might not be worth it."],
    },
    {
        text: "What is prototype inheritance and how does it work?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.javascript, ValidTag.enum.prototypes],
        answers: ["JavaScript uses prototype-based inheritance where objects can inherit properties and methods from other objects. Every object has an internal [[Prototype]] property that points to another object. When you try to access a property, JavaScript first looks on the object itself, and if it's not found, it walks up the prototype chain until it finds the property or reaches null. Functions have a prototype property that becomes the [[Prototype]] of instances created with the new keyword. While we now have class syntax in ES6, it's just syntactic sugar over this prototype system. Understanding prototypes is important for debugging and understanding how inheritance actually works under the hood, even though modern code tends to use classes for clarity."],
    },
    {
        text: "What is the module pattern and how do ES modules differ from CommonJS?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.javascript, ValidTag.enum.modules],
        answers: ["The module pattern is a way to create private scope and encapsulation, historically using IIFEs to create closures. ES modules are the modern standard using import/export syntax, while CommonJS uses require() and module.exports, mainly in Node.js. The key differences are that ES modules are statically analyzed, meaning imports are resolved at compile time, which enables tree shaking and better tooling. They're also asynchronous by nature. CommonJS loads modules synchronously and dynamically at runtime, so you can conditionally require modules. ES modules have strict mode by default and have their own scope, while CommonJS modules are wrapped in a function. In modern development, I use ES modules everywhere, though you'll still see CommonJS in older Node.js projects or configuration files."],
    },
    {
        text: "What is optional chaining and nullish coalescing?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.javascript],
        answers: ["Optional chaining, using the ?. operator, lets you safely access nested properties without having to check each level for null or undefined. If any part of the chain is nullish, it short-circuits and returns undefined instead of throwing an error. Nullish coalescing, using the ?? operator, provides a default value only when the left side is null or undefined, unlike the OR operator which triggers on any falsy value. These are game-changers for cleaner code. Instead of writing 'user && user.address && user.address.street', you can write 'user?.address?.street'. And instead of 'value || defaultValue' which fails for 0 or empty string, you use 'value ?? defaultValue'. I use these constantly when working with API responses or optional props."],
    },
    {
        text: "What is debouncing vs throttling and when would you use each?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.javascript, ValidTag.enum.performance],
        answers: ["Debouncing delays executing a function until after a certain amount of time has passed since it was last called. It's perfect for search inputs - you wait until the user stops typing before making an API call. Throttling ensures a function is only called at most once in a specified time period, regardless of how many times it's triggered. This is great for scroll or resize events where you want regular updates but not on every single pixel change. Think of debouncing as 'wait until they're done' and throttling as 'do this at regular intervals'. I use debounce for autocomplete searches with maybe a 300ms delay, and throttle for infinite scroll detection or window resize handlers. Both are essential for performance optimization."],
    },

    // TypeScript
    {
        text: "What are generics in TypeScript and how do you use them?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.typescript, ValidTag.enum.generics],
        answers: ["Generics allow you to write reusable code that works with multiple types while maintaining type safety. Instead of using 'any', you use a type parameter like <T> that acts as a placeholder for the actual type. A classic example is an array - Array<string> or Array<number>. When I write a function like 'function identity<T>(arg: T): T', TypeScript infers the type based on what you pass in. This is incredibly useful for utility functions, API response types, or component props. For instance, you might have a generic API fetch function that returns different data types, or a React component that accepts different item types. Generics let you be flexible without losing the benefits of type checking."],
    },
    {
        text: "What are union types and discriminated unions?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.typescript, ValidTag.enum.types],
        answers: ["Union types let you specify that a value can be one of several types using the pipe operator, like 'string | number'. This is useful when a function can accept multiple types or when working with different possible states. Discriminated unions, also called tagged unions, are a pattern where you have a common property (usually called 'type' or 'kind') that distinguishes between the different union members. TypeScript can then narrow the type based on that discriminant property. For example, with a Result type that's either Success or Error, each with a 'type' property, TypeScript knows if you check 'result.type === success', then result must be the Success type. I use discriminated unions all the time for state machines, API responses, or Redux actions."],
    },
    {
        text: "What is type narrowing and how does TypeScript infer types?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.typescript, ValidTag.enum["type-guards"], ValidTag.enum.types],
        answers: ["Type narrowing is when TypeScript refines a broader type to a more specific type based on your code's logic. This happens with control flow analysis - if you check 'typeof x === string', TypeScript knows x is a string in that block. It also works with truthiness checks, instanceof, and custom type guards. Type inference is TypeScript's ability to automatically determine types without explicit annotations. It looks at the value you assign, the return statements in functions, and how variables are used. For example, if you write 'const x = 5', TypeScript infers x is a number. The combination is powerful - you write minimal type annotations and TypeScript figures out the rest, while still catching type errors. I try to rely on inference when possible for cleaner code."],
    },
    {
        text: "What are utility types and when would you use Partial, Pick, Omit, Record, Required, or Readonly?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.typescript, ValidTag.enum["utility-types"]],
        answers: ["Utility types are built-in TypeScript helpers that transform existing types. Partial makes all properties optional - great for update functions where you might only change some fields. Pick extracts specific properties from a type, useful when you only need a subset. Omit is the opposite, excluding certain properties. Record creates an object type with specific keys and value types - I use this for lookup maps. Required makes all properties required, opposite of Partial. Readonly makes properties immutable. In practice, I use Partial constantly for update operations, Pick when building form types from larger entities, and Omit to exclude things like passwords from user types. Record is perfect for creating typed dictionaries. These save you from manually redefining types and keep them in sync."],
    },
    {
        text: "What is the never type and when is it used?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.typescript, ValidTag.enum.types],
        answers: ["The never type represents values that never occur. It's used for functions that never return, like ones that always throw errors or have infinite loops. It's also the type of variables in situations that should be impossible. A really useful pattern is exhaustive checking in switch statements - if you handle all cases of a union type, the default case will have type never. This way, if you add a new case to the union later and forget to handle it, TypeScript will error because you're trying to assign a real type to never. I use this pattern regularly with discriminated unions to make sure I've covered all possible states. It's a powerful tool for catching logic errors at compile time."],
    },
    {
        text: "What are declaration files and when do you need them?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.typescript],
        answers: ["Declaration files with the .d.ts extension provide type information for JavaScript code that doesn't have built-in types. They describe the shape of existing JavaScript modules without containing implementation. You need them when using JavaScript libraries in TypeScript projects. Many popular libraries ship with their own declaration files or have them available through DefinitelyTyped (@types packages). If you're working with a JavaScript library that doesn't have types, you might write your own declaration file. You also generate them when publishing a TypeScript library so consumers get type information. I've had to write custom declarations for internal JavaScript utilities or when using libraries without type definitions. They're basically type contracts without the actual code."],
    },
    {
        text: "What are index signatures and when would you use them?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.typescript, ValidTag.enum.types],
        answers: ["Index signatures let you define types for objects where you don't know the property names ahead of time, but you know the shape of the values. The syntax looks like '[key: string]: number' which means any string key will have a number value. This is useful for dictionaries, maps, or dynamic data structures. For example, if you're building a lookup table where user IDs map to user objects, you'd use an index signature. However, they're less type-safe than known properties since any string key is valid. When possible, I prefer using Record utility type or Map, but index signatures are essential when working with truly dynamic data. Just be aware that once you add an index signature, TypeScript assumes any property access is valid."],
    },

    // CSS
    {
        text: "What is the critical rendering path and how does CSS block rendering?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.css, ValidTag.enum.performance],
        answers: ["The critical rendering path is the sequence of steps browsers take to convert HTML, CSS, and JavaScript into pixels on screen. It involves building the DOM from HTML, the CSSOM from CSS, combining them into a render tree, calculating layout, and finally painting. CSS is render-blocking because the browser won't render the page until the CSSOM is complete - it needs to know all the styles before it can paint. This prevents the flash of unstyled content but can delay first paint. To optimize, you want to minimize CSS file size, inline critical CSS for above-the-fold content, and defer non-critical CSS. I usually ensure critical styles are loaded first and lazy load the rest, or use media queries to load print styles asynchronously."],
    },
    {
        text: "What causes layout thrashing and how do you avoid it?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.css, ValidTag.enum.performance],
        answers: ["Layout thrashing, or forced synchronous layout, happens when you repeatedly read layout properties and then write to the DOM in a loop. Each write invalidates the layout, and each read forces the browser to recalculate it immediately, creating a performance bottleneck. For example, reading offsetHeight and then changing styles in a loop causes this. To avoid it, you batch your reads and writes separately - read all your layout properties first, then make all your DOM changes. Libraries like FastDOM help manage this. Another approach is using requestAnimationFrame to schedule DOM updates. I also try to use CSS transforms instead of properties that trigger layout, and avoid layout properties in loops altogether when possible. It's one of those easy mistakes to make that can really hurt performance."],
    },
    {
        text: "How do you compose styles in CSS Modules?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.css, ValidTag.enum["css-modules"]],
        answers: ["CSS Modules provide composition through the 'composes' keyword, which lets you inherit styles from other classes. You can compose from classes in the same file or import from other modules. For example, 'composes: button from ./shared.module.css' would pull in the button styles. This creates multiple class names on the element but keeps your styles modular and reusable. The benefit over @extend in Sass is that it's more explicit and doesn't combine selectors. In practice, I create base component styles and compose them for variants, like a base button style that gets composed into primary, secondary, danger buttons. It keeps the CSS DRY while maintaining the scoping benefits of CSS Modules. You can also combine it with traditional class application in your components."],
    },
    {
        text: "How do you create custom utilities and components in Tailwind?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.tailwind],
        answers: ["In Tailwind, you extend the theme in tailwind.config.js to add custom values for existing utilities, like new colors or spacing. For completely new utilities, you use the addUtilities function in a plugin. For components - repeated patterns of utilities - you can use the addComponents function, though Tailwind generally discourages this in favor of composition. The preferred approach is actually creating React components or template partials that encapsulate the utility classes. For example, instead of a Button component in CSS, you'd make a Button React component with the Tailwind classes. When I do need custom utilities, like a specific text shadow pattern, I add them through plugins. The key is extending the existing system rather than fighting against it."],
    },
    {
        text: "What is the @apply directive and when should you avoid it?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.tailwind],
        answers: ["The @apply directive lets you extract Tailwind utility classes into custom CSS classes. You write something like '.btn { @apply px-4 py-2 bg-blue-500; }' to create reusable class names. While this seems convenient, Tailwind's docs actually recommend avoiding it in most cases. The problem is you lose the benefits of utility-first CSS - you're back to naming things and maintaining CSS files. It also increases bundle size since you're duplicating utilities. The better approach is component extraction at the template level with React components or partials. I only use @apply for very specific cases, like third-party component styling where I can't modify the markup, or when I absolutely need a semantic class name for a design system. For everything else, composition with components is cleaner."],
    },
    {
        text: "How does Tailwind's JIT compiler work?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.tailwind],
        answers: ["The JIT (Just-In-Time) compiler generates styles on-demand as you author your templates, rather than generating everything upfront and purging unused styles. It scans your files for class names and generates only the CSS you're actually using. This means instant build times, significantly smaller development CSS files, and the ability to use arbitrary values like 'top-[117px]' without configuration. It also enables all variants out of the box without increasing file size. The performance improvement is substantial - development builds are now as small as production builds. The way it works is through a content scanning system that watches your template files and generates CSS as it finds classes. Since JIT became the default, I've found development much faster and I use arbitrary values regularly for one-off tweaks."],
    },

    // React Core
    {
        text: "What is the React Virtual DOM and why is it important?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.react, ValidTag.enum["virtual-dom"]],
        answers: ["The Virtual DOM is React's lightweight JavaScript representation of the actual DOM. When state changes, React creates a new Virtual DOM tree, compares it with the previous one through a process called reconciliation, calculates the minimal set of changes needed, and then updates only those parts of the real DOM. This is important because direct DOM manipulation is expensive - reading and writing to it triggers reflows and repaints. By batching changes and minimizing DOM updates, React makes UI updates much more efficient. The diffing algorithm is smart enough to identify what changed and update just those nodes. While the Virtual DOM isn't always faster than direct DOM manipulation for simple cases, it provides a programming model where you can write code as if you're re-rendering everything, while React optimizes the actual updates."],
    },
    {
        text: "What are synthetic events in React?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.react, ValidTag.enum["synthetic-events"]],
        answers: ["Synthetic events are React's cross-browser wrapper around native browser events. They provide the same interface as native events but work consistently across all browsers, smoothing out inconsistencies. React implements its own event system for performance - it uses event delegation at the root level rather than attaching listeners to each element. One important thing to know is that synthetic events are pooled and reused for performance, so they're nullified after the event handler runs. If you need to access event properties asynchronously, you need to call event.persist() or store the values you need in variables. In practice, this mostly just works transparently, but it's important to understand when debugging event-related issues or doing something async with event data."],
    },
    {
        text: "How do you handle forms in React and what are the tradeoffs of different approaches?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.react, ValidTag.enum.forms],
        answers: ["There are three main approaches. Controlled components store form data in React state, with value and onChange props, giving you full control but requiring more boilerplate. Uncontrolled components use refs to access DOM values directly, which is simpler but less React-idiomatic. The third approach is using form libraries like React Hook Form or Formik. React Hook Form uses uncontrolled components under the hood with refs, minimizing re-renders and boosting performance, while Formik uses controlled components. For simple forms, controlled components are fine. For complex forms with validation, I reach for React Hook Form - it handles validation, error states, and submission with minimal re-renders. The tradeoff is learning another API, but it's worth it for forms with more than a few fields."],
    },

    // React Hooks
    {
        text: "What is useState and how does state batching work?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.react, ValidTag.enum.hooks, ValidTag.enum.useState],
        answers: ["useState is React's hook for adding state to functional components. You call it with an initial value and it returns the current state and a setter function. State batching is React's optimization where multiple setState calls in the same event handler are batched together into a single re-render. This used to only work in React event handlers, but with React 18's automatic batching, it works everywhere - timeouts, promises, and native event handlers. If you need the latest state for the next update, you use the functional form of setState that receives the previous state. It's important to understand that setState is asynchronous and batched, so you can't read the new value immediately after setting it. This batching is crucial for performance since re-rendering is expensive."],
    },
    {
        text: "What is useEffect and what are its cleanup patterns?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.react, ValidTag.enum.hooks, ValidTag.enum.useEffect],
        answers: ["useEffect lets you perform side effects in functional components - data fetching, subscriptions, manual DOM manipulation. It runs after render by default. The cleanup pattern is returning a function from useEffect that React calls before the next effect runs and when the component unmounts. This is essential for preventing memory leaks. Common cleanup scenarios include canceling API requests, clearing timers, unsubscribing from events, or closing WebSocket connections. For example, if you add an event listener, you return a function that removes it. The dependency array controls when effects run - empty array means only on mount, no array means every render, and with dependencies means when those change. The cleanup is your way of undoing whatever the effect did."],
    },
    {
        text: "What is the difference between useEffect and useLayoutEffect?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.react, ValidTag.enum.hooks, ValidTag.enum.useEffect],
        answers: ["The key difference is timing. useEffect runs asynchronously after the browser has painted, so it doesn't block visual updates. useLayoutEffect runs synchronously after DOM mutations but before the browser paints, making it blocking. Use useLayoutEffect when you need to read layout from the DOM and synchronously re-render, or when you need to make DOM mutations that the user shouldn't see. A classic case is measuring an element's size and positioning another element based on it - with useEffect you might see a flicker, but useLayoutEffect prevents that. However, because it's synchronous, it can hurt performance if you do heavy computation. In 99% of cases, useEffect is the right choice. I only reach for useLayoutEffect when I have visual bugs from async timing."],
    },
    {
        text: "What is useRef and what are its use cases beyond DOM references?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.react, ValidTag.enum.hooks, ValidTag.enum.useRef],
        answers: ["useRef creates a mutable object that persists for the component's lifetime and doesn't trigger re-renders when changed. The most common use is accessing DOM elements directly, but it's also incredibly useful for storing any mutable value that you don't want to trigger re-renders - like timer IDs, previous values, or instance variables. I use it to store interval or timeout IDs so I can clear them later, to keep track of whether a component is mounted to avoid state updates after unmount, or to store the previous value of a prop or state for comparison. Unlike state, updating ref.current doesn't cause a re-render, which is perfect for values you need to track but don't need to display. It's like having instance variables in a functional component."],
    },
    {
        text: "What is useCallback and when should you use it?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.react, ValidTag.enum.hooks, ValidTag.enum.useCallback, ValidTag.enum.performance],
        answers: ["useCallback memoizes a function so it maintains the same reference between renders unless its dependencies change. This is primarily useful when passing callbacks to optimized child components that rely on reference equality to prevent re-renders, like components wrapped in React.memo. Without useCallback, you'd create a new function on every render, causing memoized children to re-render unnecessarily. It's also useful when the function is a dependency of useEffect or other hooks, to prevent infinite loops. However, I don't use it everywhere - there's overhead to memoization itself. I only use it when I'm actually seeing performance issues or when I know I'm passing the function to a memoized component. Premature optimization with useCallback can make code harder to read without real benefit."],
    },
    {
        text: "What is useMemo and when does it actually help performance?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.react, ValidTag.enum.hooks, ValidTag.enum.useMemo, ValidTag.enum.performance],
        answers: ["useMemo memoizes a computed value, recalculating it only when its dependencies change. It's useful for expensive calculations that don't need to run on every render. However, it only helps when the computation is actually expensive - like filtering or sorting large arrays, complex mathematical operations, or deep object transformations. For simple operations, the memoization overhead might cost more than just recalculating. I also use it to maintain referential equality for objects or arrays passed to child components, similar to useCallback for functions. A good rule of thumb is to measure first - use React DevTools Profiler to identify actual performance issues before memoizing. Memoization isn't free and makes code more complex, so I only use it when I can measure the benefit."],
    },
    {
        text: "What is the difference between useCallback and useMemo?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.react, ValidTag.enum.hooks, ValidTag.enum.useCallback, ValidTag.enum.useMemo],
        answers: ["The core difference is what they memoize. useCallback memoizes a function itself, returning the same function reference between renders. useMemo memoizes the result of a function call, returning the same computed value. Technically, useCallback is just syntactic sugar - 'useCallback(fn, deps)' is equivalent to 'useMemo(() => fn, deps)'. Use useCallback when you need to pass a stable function reference to child components or dependency arrays. Use useMemo when you have an expensive computation and want to cache its result. In practice, useCallback is for preventing function identity changes, while useMemo is for avoiding expensive recalculations. Both serve performance optimization but in different ways - one caches the function, the other caches the value."],
    },
    {
        text: "What is useContext and what are its performance implications?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.react, ValidTag.enum.hooks, ValidTag.enum.useContext, ValidTag.enum.performance],
        answers: ["useContext lets you consume values from React Context without prop drilling. You pass it a context object created with createContext, and it returns the current context value from the nearest Provider above it in the tree. The main performance implication is that any component using useContext will re-render whenever the context value changes, regardless of which part of the value changed. You can't selectively subscribe to parts of the context. This can cause unnecessary re-renders in large apps. Common solutions include splitting contexts by concern, using useMemo to stabilize context values, or using state management libraries designed for performance like Zustand. Context is great for truly global or semi-global data like themes or auth, but I'm careful about putting frequently-changing data in context."],
    },
    {
        text: "What is useReducer and when would you use it over useState?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.react, ValidTag.enum.hooks, ValidTag.enum.useReducer, ValidTag.enum.useState],
        answers: ["useReducer is an alternative to useState for managing complex state. You provide a reducer function and initial state, and it returns the current state and a dispatch function. It's better than useState when you have complex state logic involving multiple sub-values, when the next state depends on the previous one, or when you want to optimize performance by passing dispatch down instead of callbacks. It's also more testable since the reducer is a pure function. I reach for useReducer for form state with multiple fields and validation, complex UI state machines, or when state updates depend on multiple actions. For simple boolean toggles or single values, useState is cleaner. It's similar to Redux but at the component level."],
    },
    {
        text: "What is useId and why was it introduced?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.react, ValidTag.enum.hooks],
        answers: ["useId generates unique IDs that are stable across server and client renders, solving a major issue with server-side rendering. Before useId, generating unique IDs was tricky because IDs generated on the server needed to match those on the client to avoid hydration mismatches. It's primarily used for accessibility attributes that require unique IDs, like linking labels to inputs with htmlFor and id, or aria attributes. You call it with no arguments and it returns a unique string. It's important to note that it's not for generating keys in lists - those should be based on your data. The IDs it generates aren't sequential or pretty, but they're guaranteed to be unique and consistent across renders. I use it whenever I need to connect related elements for accessibility."],
    },

    // State Management
    {
        text: "What is Redux and how does the data flow work?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.redux, ValidTag.enum.react],
        answers: ["Redux is a predictable state management library based on a single source of truth - the store. The data flow is unidirectional: components dispatch actions, which are plain objects describing what happened. Reducers, which are pure functions, take the current state and an action, and return a new state. The store updates with this new state and notifies subscribed components to re-render. This pattern makes state changes predictable and debuggable. You can see exactly what changed, when, and why. Redux DevTools let you time-travel through state changes. The downside is boilerplate - you need action creators, reducers, and often middleware for async operations. Redux Toolkit significantly reduces this. I use Redux for complex applications with lots of shared state, but for simpler apps, Context or Zustand might be sufficient."],
    },
    {
        text: "What is Zustand and why would you choose it over Redux?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.zustand, ValidTag.enum.react],
        answers: ["Zustand is a small, fast state management library with a much simpler API than Redux. You create a store with a single function call, and state updates are straightforward - you just mutate a draft using Immer under the hood or return new state. Components can subscribe to specific slices of state, preventing unnecessary re-renders. Unlike Context, it doesn't require providers wrapping your app. The main advantages over Redux are less boilerplate, smaller bundle size, better performance with selective subscriptions, and no need for actions or reducers. The tradeoff is less structure and fewer guardrails. I prefer Zustand for most projects now because it's so much simpler while still providing good developer experience. Redux is still valuable for very large apps where you want the strict patterns and extensive ecosystem."],
    },
    {
        text: "What are the performance implications of React Context?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.react, ValidTag.enum["context-api"], ValidTag.enum.performance],
        answers: ["The main performance issue with Context is that every component consuming the context re-renders whenever the context value changes, even if it only uses a small part of that value. There's no way to selectively subscribe to portions of the context. This can cause cascading re-renders in large component trees. To mitigate this, you can split contexts by concern so changes to one don't affect others, use useMemo to prevent creating new context values on every render, or leverage composition to limit which components actually consume the context. For frequently changing data, Context might not be the best choice - libraries like Zustand or Jotai provide more granular subscriptions. Context is great for relatively static data like themes, auth state, or configuration, but be cautious with rapidly changing application state."],
    },
    {
        text: "How do you structure global state vs server state vs local state?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.react],
        answers: ["I think about these as distinct categories that need different solutions. Local state is component-specific data like form inputs or UI toggles - useState or useReducer handles this perfectly. Global client state is application-level data that's not from the server, like UI preferences, modal state, or selected themes - I use Context, Zustand, or Redux depending on complexity. Server state is data from your backend, which is fundamentally different because it's cached, can be stale, and needs refetching - TanStack Query or SWR are purpose-built for this. The key insight is that server state shouldn't go into Redux or Context; it needs different handling for caching, revalidation, and synchronization. I've seen many projects mix these concerns and end up with complicated state management when they just needed to separate server state properly."],
    },
    {
        text: "How do you handle derived state?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.react, ValidTag.enum.state],
        answers: ["Derived state is data you can compute from existing state, and the key principle is to avoid storing it as separate state. Instead, calculate it during render or use useMemo if the calculation is expensive. For example, if you have an array of items and need the filtered count, don't store both the array and the count - just calculate filteredItems.length. Storing derived state separately leads to synchronization bugs where the states get out of sync. If you're tempted to use useEffect to keep derived state in sync, that's a code smell - you should usually just compute it directly. The exception is when the computation is truly expensive and you're seeing performance issues, then useMemo is appropriate. This keeps your state minimal and your components easier to reason about."],
    },

    // TanStack Query
    {
        text: "What is TanStack Query and what problems does it solve?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum["tanstack-query"], ValidTag.enum.react],
        answers: ["TanStack Query, formerly React Query, is a data-fetching and caching library that handles server state. It solves the problems of fetching, caching, synchronizing, and updating server data. Without it, you'd manually handle loading states, error states, caching, deduplication, background refetching, and stale data. TanStack Query does all this automatically. It caches query results, deduplicates identical requests, automatically refetches in the background to keep data fresh, handles pagination and infinite scrolling, and provides a great DevTools experience. It shifts your mental model from thinking about when to fetch to describing what data you need. The really powerful part is how it handles cache invalidation and refetching. I use it on every project now - it dramatically reduces boilerplate and makes data fetching predictable."],
    },
    {
        text: "What is the difference between useQuery and useMutation?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum["tanstack-query"], ValidTag.enum.react],
        answers: ["useQuery is for fetching data - it runs automatically, returns cached data, and manages refetching. You use it for GET requests that read data. It handles loading, error, and success states, and the data is cached by the query key. useMutation is for modifying data - POST, PUT, DELETE requests. It doesn't run automatically; you call the mutate function when you want to perform the operation. Mutations don't cache results but can invalidate or update query caches after success. A typical pattern is using useQuery to fetch a list, useMutation to add an item, and then invalidating the list query in the mutation's onSuccess callback so the list refetches. I use queries for all my data reads and mutations for writes, and they work together to keep the UI in sync with the server."],
    },
    {
        text: "What is stale-while-revalidate and how does TanStack Query implement it?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum["tanstack-query"], ValidTag.enum.caching],
        answers: ["Stale-while-revalidate is a caching strategy where you immediately return cached data even if it's stale, then refetch in the background and update when fresh data arrives. This provides instant UI updates while ensuring data freshness. TanStack Query implements this through staleTime and cacheTime configs. StaleTime determines how long data is considered fresh - during this period, no refetch happens. After it becomes stale, the cached data is still returned, but a background refetch is triggered. CacheTime determines how long unused data stays in cache. This means users see instant responses from cache while getting fresh data shortly after. It's a great UX pattern - no loading spinners for cached data, but data stays up to date. I typically set different stale times based on how frequently data changes."],
    },
    {
        text: "How does query caching work in TanStack Query?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum["tanstack-query"], ValidTag.enum["query-cache"], ValidTag.enum.caching],
        answers: ["TanStack Query caches query results in memory, keyed by the query key. When you call useQuery with a key that's already cached, it returns the cached data immediately while potentially refetching in the background based on your staleness config. Each query has status tracking - fresh, stale, or fetching. Fresh queries won't refetch, stale queries will refetch in certain situations like window focus or mount. The cache persists as long as there are active subscribers or until cacheTime expires for inactive queries. You can manually manipulate the cache with invalidation to mark data as stale, or direct updates to modify cached data without refetching. This intelligent caching means the same data across your app shares a single cache entry, preventing duplicate requests and keeping everything in sync."],
    },
    {
        text: "What are query keys and how should you structure them?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum["tanstack-query"], ValidTag.enum["query-keys"]],
        answers: ["Query keys uniquely identify queries for caching purposes. They can be strings or arrays, and TanStack Query uses them to determine if cached data exists and to match queries for invalidation. Best practice is to structure them as arrays hierarchically, from least to most specific. For example, ['todos'] for all todos, ['todos', 'list', { filter: 'completed' }] for filtered todos, and ['todos', 'detail', id] for a specific todo. This structure lets you invalidate at any level - invalidating ['todos'] refetches all todo-related queries, while ['todos', 'detail', 5] only refetches that specific todo. Include all variables that affect the data in the key. I treat query keys as dependencies - if any parameter changes, it should be in the key to trigger a new fetch."],
    },
    {
        text: "What is query invalidation and when would you use it?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum["tanstack-query"]],
        answers: ["Query invalidation marks cached data as stale and triggers a refetch for active queries. You use queryClient.invalidateQueries() with a query key or pattern. The most common use case is after mutations - when you create, update, or delete data, you invalidate related queries so they refetch and show the updated data. For example, after adding a todo, you'd invalidate the todos list query. You can invalidate exact matches or use partial keys to invalidate multiple related queries. It's more efficient than manually updating the cache for complex data relationships. Sometimes I combine approaches - optimistically update the cache for instant UI feedback, then invalidate to refetch and ensure consistency. Invalidation is your primary tool for keeping the UI in sync with the server after changes."],
    },
    {
        text: "How do you handle dependent queries?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum["tanstack-query"]],
        answers: ["Dependent queries are when one query needs data from another query to run. TanStack Query handles this with the enabled option. You set enabled to false until you have the required data. For example, if you need a user ID from a user query before fetching that user's projects, you'd do 'enabled: !!userId'. The query won't execute until enabled becomes true. This prevents unnecessary requests and errors from missing parameters. You can also chain data - the second query can use data from the first query's result. Another pattern is using query keys with the dependent data, so when that data changes, the dependent query automatically refetches. This keeps everything reactive and in sync. I use dependent queries frequently when building features that require sequential data fetching."],
    },
    {
        text: "How do you handle error and loading states?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum["tanstack-query"], ValidTag.enum.react],
        answers: ["TanStack Query provides comprehensive state through the query result object. You get isLoading for initial load, isFetching for any fetch including background refetches, isError and error for error states, and isSuccess with data for successful states. For most UIs, I check isLoading to show a skeleton, isError to show an error message, and then render data. For more sophisticated UIs, I might show background refetch indicators using isFetching. You can also use status which is 'loading', 'error', or 'success' as a string. Error handling can be global through QueryClient defaults or per-query with onError callbacks. I typically combine local error displays with global error boundaries. The status booleans are mutually exclusive which makes conditional rendering straightforward."],
    },

    // Next.js
    {
        text: "What is Next.js and what problems does it solve over plain React?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.nextjs, ValidTag.enum.react],
        answers: ["Next.js is a React framework that adds server-side rendering, static site generation, routing, and other production features on top of React. Plain React is client-side only - the browser downloads JavaScript, executes it, and builds the page, which hurts SEO and initial load time. Next.js solves this by rendering pages on the server, sending fully formed HTML to the browser, then hydrating it with React. This improves performance and SEO dramatically. It also provides file-based routing, API routes, automatic code splitting, image optimization, and built-in CSS support. You get a lot of configuration and tooling out of the box that you'd otherwise need to set up yourself with webpack, Babel, routing libraries, etc. For any production React app, especially content sites, Next.js saves tons of setup time."],
    },
    {
        text: "What is the difference between SSR, SSG, and ISR?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.nextjs, ValidTag.enum.ssr, ValidTag.enum.ssg, ValidTag.enum.isr],
        answers: ["SSR (Server-Side Rendering) generates HTML on every request. It's always fresh but slower since the server does work on each request. Use it for personalized or frequently changing data. SSG (Static Site Generation) generates HTML at build time. It's incredibly fast since it's just serving static files, but data can be stale. Perfect for blogs, docs, or marketing pages. ISR (Incremental Static Regeneration) is the sweet spot - it serves static pages like SSG but regenerates them in the background after a specified interval. You get the speed of static sites with fresher data. After the revalidation period, the next visitor triggers a rebuild in the background while still seeing the stale page. I use SSG for mostly static content, ISR for content that changes occasionally, and SSR only when data must be fresh on every request."],
    },
    {
        text: "When would you use server-side rendering vs client-side rendering?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.nextjs, ValidTag.enum.ssr, ValidTag.enum.csr],
        answers: ["Server-side rendering is better for SEO-critical content, when you need fast initial page loads, or when serving users with slower devices or connections. The initial HTML is ready immediately. Client-side rendering is fine for authenticated dashboards, internal tools, or highly interactive apps where SEO doesn't matter. It's simpler and reduces server load. The tradeoff is SSR adds server complexity and costs, while CSR means slower initial loads and poor SEO. In practice, I often use a hybrid approach - SSR for public pages that need SEO like landing pages and blogs, and CSR for the authenticated portions of the app. Next.js makes this easy since you can mix rendering strategies per page. The right choice depends on your audience and whether search engines need to see your content."],
    },
    {
        text: "How does Next.js handle routing?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.nextjs, ValidTag.enum.routing],
        answers: ["Next.js uses file-based routing where the file structure in the pages directory maps to routes. A file at pages/about.js becomes /about, pages/blog/index.js becomes /blog, and so on. Dynamic routes use square brackets like [id].js which matches any value and provides it as a query parameter. You can have catch-all routes with [...slug].js. The router is available through next/router with push, replace, and query. The Link component handles client-side navigation with prefetching. This file-based approach eliminates the need for route configuration files and makes the structure intuitive. With the new App Router, it's now folder-based with more features, but the Pages Router is still widely used. I find file-based routing much simpler than manually configuring React Router."],
    },
    {
        text: "What is the _app.js file and what is it used for?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.nextjs, ValidTag.enum["pages-router"]],
        answers: ["The _app.js file is the root component that wraps all pages in a Next.js application. It's where you put anything that should persist across page changes - layout components, global styles, theme providers, authentication wrappers, state management providers, or analytics initialization. Every page is passed as the Component prop along with pageProps. You can override _app to customize the initialization process, add global error boundaries, or track page views. Common use cases include wrapping the app in a Redux Provider, adding a persistent navigation bar, or including global CSS imports. Anything you put in _app wraps every page, so be mindful of performance. I typically keep _app minimal and compose layout components at the page level when possible."],
    },
    {
        text: "How does Next.js handle image optimization?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.nextjs, ValidTag.enum.performance],
        answers: ["The Next.js Image component automatically optimizes images by serving them in modern formats like WebP when supported, lazy loading by default, preventing layout shift with automatic sizing, and resizing images based on the device. It serves responsive images with the right size for each viewport. Images are optimized on-demand when requested, not at build time, so it works for any number of images. The component requires width and height props to prevent layout shift, or you can use fill for responsive sizing. You can configure custom image loaders for CDNs. This automatic optimization is huge for performance - images are often the largest assets on web pages. I use next/image for every image now because it handles all the optimization best practices automatically."],
    },
    {
        text: "What is next/head and how do you manage metadata?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.nextjs, ValidTag.enum.seo],
        answers: ["next/head is a component that lets you modify the document head for each page, adding title tags, meta descriptions, Open Graph tags, or any other head elements. You import Head from next/head and use it anywhere in your component. This is crucial for SEO since each page can have unique metadata. If multiple Head components specify the same tag, the last one wins, so you can have defaults in _app and override them per page. For the App Router, this is replaced by the metadata export or generateMetadata function which is more ergonomic. I always set title, description, and Open Graph tags for public pages. This proper metadata is essential for search rankings and social media sharing."],
    },
    {
        text: "How do you handle environment variables in Next.js?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.nextjs],
        answers: ["Next.js loads environment variables from .env.local for local development and .env.production for production builds. Variables are automatically available in Node.js code through process.env. For client-side code, you must prefix variables with NEXT_PUBLIC_ to expose them - this is a security feature to prevent accidentally exposing server secrets. Variables without the prefix are only available server-side. You can also have .env.development for development-specific values. The precedence is .env.local overrides .env, and specific environments override general. Never commit .env.local to version control - use .env for defaults that can be committed. I keep API keys and secrets in .env.local, and only expose public API endpoints with NEXT_PUBLIC_ prefix for client-side use."],
    },
    {
        text: "What is the public folder and how does static file serving work?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.nextjs],
        answers: ["The public folder in Next.js is for static assets that should be served as-is without processing. Files in public are available at the root URL path - so public/logo.png is accessible at /logo.png. This is perfect for robots.txt, favicons, images, fonts, or any other static files. Important: don't use 'public' in the path when referencing these files, just start with a slash. These files are served directly and don't go through webpack, so they won't be optimized. For images you want optimized, you should still use the Image component and can reference public folder images. I use public for assets that must have specific URLs or filenames like robots.txt, and for assets that are already optimized and don't need processing."],
    },
    {
        text: "What is getStaticProps and when would you use it?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.nextjs, ValidTag.enum["pages-router"], ValidTag.enum.ssg],
        answers: ["getStaticProps is a function you export from a page that runs at build time to fetch data for static generation. It runs on the server, never on the client, so you can directly query databases or access the filesystem. The data it returns as props is baked into the HTML at build time. Use it for pages with data that doesn't change often or can be the same for all users - blogs, marketing pages, documentation. You can add a revalidate value to enable ISR, so the page regenerates in the background after that interval. The advantage is performance - the HTML is pre-generated and served instantly. The tradeoff is the data is only as fresh as the last build or revalidation. I use it for most content-driven pages."],
    },
    {
        text: "What is getServerSideProps and what are its performance implications?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.nextjs, ValidTag.enum["pages-router"], ValidTag.enum.ssr, ValidTag.enum.performance],
        answers: ["getServerSideProps runs on every request, fetching data server-side and rendering the page with that data before sending it to the client. Use it when data must be fresh on every request or is user-specific. It has access to the request object so you can check cookies, headers, or query params. The performance implication is that it's slower than static generation - every request waits for the server to fetch data and render. This adds server load and costs. It can't be cached by CDNs in the same way. Time to first byte is slower. I only use it when absolutely necessary - for authenticated, personalized data or when data changes so frequently that ISR won't work. Often, client-side fetching with SWR or TanStack Query is a better choice if the initial SEO HTML doesn't need the data."],
    },
    {
        text: "What is getStaticPaths and how does dynamic routing work?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.nextjs, ValidTag.enum["pages-router"], ValidTag.enum["dynamic-routes"]],
        answers: ["getStaticPaths is required when you have dynamic routes with getStaticProps. It tells Next.js which dynamic pages to pre-render at build time. You return an array of params objects representing each page to generate. For a blog, you'd fetch all post IDs and return paths for each. The fallback option controls what happens for paths not returned - false means 404, true shows a fallback while generating, and 'blocking' waits for generation. For thousands of pages, you might only pre-render popular pages and set fallback to 'blocking' to generate others on-demand. This combines static generation's speed with the flexibility of dynamic content. I use getStaticPaths for blogs and product pages - pre-render at build time but handle new content gracefully."],
    },
    {
        text: "How do API routes work in the Pages Router?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.nextjs, ValidTag.enum["pages-router"], ValidTag.enum["api-routes"]],
        answers: ["API routes let you build API endpoints inside your Next.js app. Files in pages/api map to /api/* endpoints. You export a function that receives req and res objects, similar to Express. These run as serverless functions and can access databases, external APIs, or the filesystem. They're great for hiding API keys, handling authentication, or creating simple backends without deploying a separate server. You can use them for webhooks, form submissions, or proxy requests. They support dynamic routes just like pages. The limitation is they're serverless, so not ideal for long-running processes or WebSockets. I use them for simple backend logic, authentication endpoints, and proxying third-party APIs to hide credentials."],
    },
    {
        text: "What is ISR (Incremental Static Regeneration) and when would you use it?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.nextjs, ValidTag.enum.isr, ValidTag.enum.performance],
        answers: ["ISR lets you update static pages after build without rebuilding the entire site. You add a revalidate value in seconds to getStaticProps. After that time, the next visitor gets the cached stale page, but triggers a regeneration in the background. Once regenerated, subsequent visitors get the fresh page. This gives you the performance of static sites with content that updates periodically. It's perfect for content that changes regularly but doesn't need to be real-time - product listings, blog posts, news articles. The sweet spot is content that changes hourly or daily. I might use 60 seconds for product prices, 3600 for blog posts. The beautiful part is it scales infinitely since you're mostly serving cached pages, but content stays reasonably fresh."],
    },

    // React Native
    {
        text: "What is React Native and how does it differ from React?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum["react-native"], ValidTag.enum.react],
        answers: ["React Native is a framework for building native mobile apps using React. The core difference is the rendering target - React renders to the DOM, while React Native renders to native platform components. Instead of div and span, you use View and Text. Instead of CSS, you use StyleSheet which is similar but not identical. The JavaScript runs in a JS engine, but the UI is actual native components, not a WebView. This gives you native performance and feel. You write mostly the same React code with hooks and components, but the platform APIs and components are different. The development experience is similar - hot reloading, component-based architecture. You can share business logic between web and mobile but not UI code. It's a great choice when you want native apps without learning Swift or Kotlin."],
    },
    {
        text: "What is the bridge in React Native and how does it work?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum["react-native"]],
        answers: ["The bridge is the communication layer between JavaScript and native code in React Native. Your JavaScript runs in a separate thread from the UI, and they communicate by passing serialized JSON messages over the bridge. When you update state, React Native serializes the changes, sends them over the bridge, and the native side updates the UI. This asynchronous communication is a potential performance bottleneck - too many messages or large payloads can cause slowdowns. That's why you minimize bridge traffic and avoid rapid updates. The new architecture with JSI (JavaScript Interface) is replacing the bridge with direct JavaScript-to-native calls, which is much faster. But in current React Native, understanding the bridge helps you optimize performance by reducing unnecessary communication."],
    },
    {
        text: "What is the difference between React Native and Expo?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum["react-native"]],
        answers: ["React Native is the core framework, while Expo is a set of tools and services built on top of it. Expo provides a managed workflow where you don't deal with native code - you just write JavaScript and Expo handles the native layer. It includes a bunch of commonly needed APIs like camera, location, and notifications out of the box. The Expo Go app lets you preview on real devices without building. The downside is you're limited to Expo's supported modules - you can't add arbitrary native code. Expo has a bare workflow that gives you more control while keeping some Expo tools. Plain React Native requires managing iOS and Android projects and writing native modules when needed. I start with Expo for most projects and only eject if I need custom native functionality."],
    },
    {
        text: "What are the core components in React Native?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum["react-native"]],
        answers: ["The fundamental components are View (like div, a container), Text (for displaying text - all text must be in Text components), Image (for images), ScrollView (scrollable container), TextInput (for user input), and TouchableOpacity or Pressable (for touchable elements). View is your main layout building block using flexbox. Text is required for any text content. ScrollView makes content scrollable but renders everything at once. For long lists, you use FlatList or SectionList which are optimized with virtualization. Button is basic but limited, so you often use Touchables to make custom buttons. SafeAreaView handles notches and safe areas. Modal creates overlays. These primitives combine to build complex UIs just like HTML elements, but they map to native components."],
    },
    {
        text: "What is the difference between StyleSheet and inline styles in React Native?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum["react-native"], ValidTag.enum.performance],
        answers: ["StyleSheet is React Native's API for creating optimized style objects. You call StyleSheet.create() with an object of styles, and it returns an optimized reference. Inline styles are plain JavaScript objects passed directly to the style prop. The key difference is performance - StyleSheet objects are created once and reused, while inline styles create new objects on every render, potentially causing unnecessary re-renders. StyleSheet also validates styles in development, catching typos. However, inline styles are fine for dynamic styles that actually change, like interpolated values in animations. I use StyleSheet for static styles defined once, and inline styles only when I need to compute styles based on props or state. The performance difference isn't huge but it's a best practice."],
    },
    {
        text: "How do you handle platform-specific code in React Native?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum["react-native"]],
        answers: ["React Native provides several ways to handle platform-specific code. The Platform module has a Platform.OS property that's 'ios' or 'android', so you can write conditional logic. Platform.select() is cleaner for choosing between values. For larger differences, you can use file extensions like Component.ios.js and Component.android.js, and React Native automatically imports the right one. This is great when entire components need to differ. You can also use platform-specific native modules when JavaScript isn't enough. I use Platform.select for small style differences, separate files when the components diverge significantly, and try to keep most code shared. The goal is to maximize code reuse while handling the inevitable platform differences gracefully."],
    },
    {
        text: "What is the difference between FlatList and ScrollView?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum["react-native"], ValidTag.enum.performance],
        answers: ["ScrollView renders all children immediately, even if they're off-screen. This is fine for short lists but terrible for performance with hundreds of items. FlatList only renders items currently visible on screen plus a small window around them, using virtualization. As you scroll, it unmounts off-screen items and mounts new ones. This keeps memory usage constant regardless of list length. FlatList is built for data arrays - you pass data and a renderItem function. It also has built-in optimizations like item keys and performance props. Use ScrollView for small, known-size content. Use FlatList for any data-driven list, especially if it could grow. SectionList is similar to FlatList but supports sections with headers. I default to FlatList for any list of data."],
    },
    {
        text: "How do you debug React Native applications?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum["react-native"], ValidTag.enum.debugging],
        answers: ["React Native has several debugging options. The Dev Menu (shake device or Cmd+D) gives access to features like remote debugging with Chrome DevTools, enabling Fast Refresh, and showing the element inspector. You can use console.log which appears in Metro bundler logs. React DevTools work for inspecting the component tree. For JavaScript debugging, you can use Flipper, which is the recommended debugger with network inspection, layout inspection, and logs. Reactotron is another popular tool. For native crashes, you use Xcode or Android Studio debuggers. The network inspector shows API calls. For performance, you can enable performance monitor to see FPS. I usually start with console.log, use React DevTools for component issues, and Flipper for network and comprehensive debugging."],
    },
    {
        text: "How do you handle navigation in React Native?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum["react-native"], ValidTag.enum.routing],
        answers: ["React Navigation is the most popular navigation library for React Native. It provides several navigator types - Stack for screen stacks like iOS navigation, Tab for bottom tabs, Drawer for side menus, and you can combine them. You define a navigation structure, and it handles transitions, gestures, and state. Each screen gets a navigation prop for navigating and passing params. Stack navigation feels native with platform-appropriate transitions. React Navigation is JavaScript-based, so it's highly customizable. There's also React Native Navigation which uses native navigation primitives for better performance but is less flexible. Expo Router is a newer file-based routing solution. I typically use React Navigation for most apps since it covers 95% of navigation needs with great DX."],
    },

    // Accessibility
    {
        text: "What is accessibility and why does it matter?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.accessibility, ValidTag.enum.a11y],
        answers: ["Accessibility, often abbreviated a11y, means making your application usable by everyone, including people with disabilities. This includes visual impairments requiring screen readers, motor impairments needing keyboard navigation, hearing impairments needing captions, and cognitive impairments benefiting from clear interfaces. It matters ethically because everyone deserves access to digital content. Legally, many jurisdictions require it. Practically, it improves UX for everyone - keyboard shortcuts help power users, captions help in noisy environments, clear labels reduce confusion. About 15% of the world has some disability, so you're excluding a significant audience without accessibility. Plus, many accessibility practices overlap with SEO. I consider accessibility from the start rather than retrofitting, and it's usually not much extra work if you do it right."],
    },
    {
        text: "What are WCAG guidelines?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.accessibility, ValidTag.enum.wcag],
        answers: ["WCAG (Web Content Accessibility Guidelines) are the international standard for web accessibility, created by W3C. They're organized around four principles: Perceivable, Operable, Understandable, and Robust. There are three conformance levels - A (basic), AA (mid-range, most commonly targeted), and AAA (highest). WCAG covers things like providing text alternatives for images, ensuring sufficient color contrast, making all functionality keyboard accessible, giving users enough time to read content, and avoiding content that could cause seizures. Version 2.1 is current, with 2.2 adding more criteria. Most legal requirements reference WCAG AA compliance. I use it as a checklist for accessibility - things like 4.5:1 contrast ratio for normal text, alt text for images, and proper heading structure are all WCAG requirements."],
    },
    {
        text: "What is the difference between ARIA roles and semantic HTML?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.accessibility, ValidTag.enum.aria, ValidTag.enum["semantic-html"]],
        answers: ["Semantic HTML uses elements that convey meaning - button, nav, article, header. These have built-in accessibility features and roles. ARIA (Accessible Rich Internet Applications) is a set of attributes you add to HTML to provide additional accessibility information, like role='button' or aria-label. The key principle is: use semantic HTML first, ARIA only when semantic HTML isn't sufficient. A real button is better than a div with role='button' because it's keyboard accessible by default and has expected behavior. ARIA is for complex widgets that don't have native HTML equivalents, like tabs or accordions, or to provide extra context like aria-live regions. Misusing ARIA can make things worse for screen reader users. I use semantic HTML whenever possible and ARIA to fill gaps."],
    },
    {
        text: "What is focus management and why does it matter?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.accessibility, ValidTag.enum["focus-management"]],
        answers: ["Focus management is controlling which element has keyboard focus and ensuring a logical focus order. It's critical for keyboard and screen reader users who navigate by focus. Focus should follow a logical order matching the visual layout, usually top to bottom, left to right. When you open a modal, focus should move into it and trap there until closed, then return to the trigger. Skip links let users bypass repetitive navigation. You shouldn't remove focus outlines unless replacing them with equally visible indicators. Custom components need proper tabIndex and focus handling. When content changes, like after deleting an item, focus should move somewhere logical. I test all interactions with keyboard-only navigation to ensure focus is always visible and logical. React refs and focus management is key for modals and dynamic content."],
    },

    // Testing
    {
        text: "What is React Testing Library and how does it differ from Enzyme?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.testing, ValidTag.enum.rtl, ValidTag.enum.react],
        answers: ["React Testing Library is a testing library focused on testing components the way users interact with them, rather than implementation details. Enzyme, the older alternative, provides utilities to test component internals like state and props. The philosophy difference is key - RTL encourages testing behavior and output, while Enzyme encourages testing implementation. RTL doesn't let you access state or simulate lifecycle methods directly. Instead, you query by text, labels, roles - things users see. This makes tests more resilient to refactoring since changing how something works internally won't break tests as long as the output is the same. Enzyme tests often break when you refactor. RTL has become the standard and is recommended by the React team. I use RTL exclusively now for this reason."],
    },
    {
        text: "What are the guiding principles of React Testing Library?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.testing, ValidTag.enum.rtl, ValidTag.enum.react],
        answers: ["The core principle is: test your software the way users use it. This means querying elements the way users find them - by label text, displayed text, or role, not by implementation details like class names or component state. Tests should resemble how your app is used. This makes tests more maintainable because they don't break when you refactor implementation. Another principle is avoiding testing implementation details - don't test state, props, or component methods directly. Focus on inputs and outputs. Also, find elements by accessibility attributes when possible, which encourages accessible markup. The philosophy is that if your tests use the app like a user, they'll be valuable and maintainable. This has completely changed how I write tests for the better."],
    },
    {
        text: "What are the different query methods and when do you use each?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.testing, ValidTag.enum.rtl],
        answers: ["RTL has three types of queries: getBy, queryBy, and findBy, each with variants like getByRole, getByText, etc. getBy throws an error if the element isn't found - use it for elements that should be in the document. queryBy returns null if not found - use it to assert something doesn't exist. findBy returns a promise and waits for the element to appear - use it for async elements that show up after data loads or user interaction. Then there are AllBy variants for multiple matches. For query types, prefer getByRole for accessibility, getByLabelText for form fields, getByPlaceholderText as a last resort for inputs, and getByText for non-interactive text. getByTestId is an escape hatch when nothing else works. I follow the priority order: role, label, placeholder, text, test ID."],
    },
    {
        text: "How do you test user interactions?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.testing, ValidTag.enum.rtl, ValidTag.enum.react],
        answers: ["You use the userEvent library or fireEvent from RTL. userEvent is preferred because it simulates complete user interactions more accurately - like typing triggers keydown, keypress, and keyup events. fireEvent just dispatches single events. For clicks, you do userEvent.click(button). For typing, userEvent.type(input, 'text'). You can simulate hover, tab navigation, selecting options, and more. The pattern is: render the component, find elements using queries, interact with them using userEvent, then assert the result. For async results, you use waitFor or findBy queries to wait for changes. Always wrap assertions about async changes in waitFor. I use userEvent for all interactions because it better matches real user behavior and catches more potential bugs."],
    },
    {
        text: "How do you test components with context?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.testing, ValidTag.enum.rtl, ValidTag.enum.react],
        answers: ["You wrap the component in the necessary context providers when rendering in tests. RTL's render function accepts a wrapper option where you can provide a component that wraps your test component. You can create a custom render function that includes all your common providers - theme, auth, router, etc. This keeps tests clean. If you need different context values per test, you pass them as props to your wrapper. For testing the context provider itself, you render a consumer component inside it and assert the values are correct. Mock the context values when you want to test different states. I create a custom render that includes all standard providers, then override specific values per test when needed."],
    },
    {
        text: "How do you test components with hooks?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.testing, ValidTag.enum.rtl, ValidTag.enum.react, ValidTag.enum.hooks],
        answers: ["For components using hooks, you test them like any other component - render, interact, assert. RTL doesn't care about implementation details like hooks. For testing custom hooks in isolation, you use renderHook from @testing-library/react. It renders a test component that calls your hook and returns the result. You can access result.current to get the hook's return value, and rerender to trigger updates. For hooks with side effects, use waitFor for async assertions. You can pass props to test different inputs. The pattern is similar to component testing but focused on the hook's interface. I usually test custom hooks in isolation to verify their logic, then test components using those hooks to verify integration."],
    },

    // Git
    {
        text: "What is git reflog and when would you use it?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.git],
        answers: ["Git reflog is a record of where your HEAD and branch references have been, even including commits that are no longer reachable from any branch. It's like a safety net for your local repository. I use it when I accidentally reset to the wrong commit, delete a branch, or mess up a rebase. You can find the commit SHA you need and recover it with git reset or git cherry-pick. Reflog entries expire after 90 days by default. A common scenario is accidentally doing a hard reset and needing to get back to where you were - reflog shows all the previous HEAD positions so you can restore them. It's purely local and not shared with the remote. It's saved me many times when I've made mistakes with Git operations."],
    },
    {
        text: "What is the difference between git reset and git revert?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.git],
        answers: ["Git reset moves the current branch pointer to a different commit, potentially removing commits from the branch history. It rewrites history, which is dangerous for shared branches. Git revert creates a new commit that undoes the changes from a previous commit, preserving history. Reset is like going back in time and pretending something never happened, while revert is like creating an undo operation that shows you reverted something. Use reset for local commits you haven't pushed yet. Use revert for commits that are already on shared branches because it doesn't rewrite history. I use reset to clean up my local work before pushing, and revert when I need to undo something that's already been shared with the team."],
    },
    {
        text: "What are the different modes of git reset (soft, mixed, hard)?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.git],
        answers: ["Git reset has three modes that differ in what they do with your changes. Soft reset moves the branch pointer but keeps your changes staged and in the working directory - use it when you want to redo a commit with different changes. Mixed reset, the default, moves the pointer and unstages changes but keeps them in your working directory - use it when you want to recommit with different staging. Hard reset moves the pointer and discards all changes in staging and working directory - use it when you want to completely throw away work. A common use for soft is squashing commits by resetting back and recommitting. Mixed is good for unstaging everything. Hard is dangerous but useful when you want to match a remote state exactly. I use hard reset carefully since it destroys work."],
    },
    {
        text: "What is cherry-picking?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.git, ValidTag.enum["cherry-pick"]],
        answers: ["Cherry-picking is applying a specific commit from one branch to another. You use git cherry-pick with a commit SHA to copy that commit's changes onto your current branch as a new commit. It's useful when you need a specific fix from another branch but don't want to merge the whole branch. For example, if you have a bug fix on a feature branch but need it on main immediately, you can cherry-pick just that commit. The downside is it creates duplicate commits with different SHAs, which can complicate history. It's better to use proper merging or rebasing when possible. I use cherry-pick sparingly, mainly for hotfixes that need to go to multiple branches or when extracting specific work from a messy branch."],
    },
    {
        text: "What is GitFlow vs trunk-based development?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.git, ValidTag.enum.branching],
        answers: ["GitFlow is a branching model with long-lived branches like develop and main, plus feature, release, and hotfix branches. It's structured but complex. Trunk-based development has everyone committing to a single main branch frequently, using short-lived feature branches or feature flags. GitFlow works well for scheduled releases and when you need to support multiple versions. Trunk-based development is better for continuous deployment and faster feedback. GitFlow can lead to merge hell with long-lived branches. Trunk-based requires good testing and CI/CD since main is always deployable. Modern development trends toward trunk-based with continuous deployment. I prefer trunk-based for web apps with continuous deployment, but GitFlow can make sense for mobile apps with release schedules and app store reviews."],
    },
    {
        text: "What are Git hooks?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.git],
        answers: ["Git hooks are scripts that Git executes before or after events like commit, push, or merge. They live in .git/hooks and can be written in any scripting language. Common hooks include pre-commit for running linters or tests before committing, commit-msg for validating commit message format, pre-push for running tests before pushing, and post-merge for updating dependencies after pulling. Hooks are local by default, but tools like Husky let you share them via package.json. I use pre-commit hooks to run prettier and eslint, ensuring code is formatted and linted before committing. Pre-push hooks can run tests to prevent broken code from being pushed. The downside is they can slow down Git operations if they do too much work."],
    },

    // Performance
    {
        text: "How would you optimize a slow loading page?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.performance, ValidTag.enum.debugging],
        answers: ["I'd start by measuring to identify bottlenecks using Lighthouse or Chrome DevTools Performance panel. Common issues and fixes include: large bundle sizes - implement code splitting and lazy loading; unoptimized images - compress and use modern formats like WebP with proper sizing; too many network requests - bundle assets, use HTTP/2, implement caching; blocking JavaScript - defer non-critical scripts, async load when possible; slow API responses - implement caching, consider SSR or SSG; no CDN - serve static assets from a CDN; layout shifts - define dimensions for images and dynamic content. I prioritize based on impact - often images are the biggest win. The key is measuring first, fixing the biggest issues, then measuring again. Every optimization should be based on data, not assumptions."],
    },
    {
        text: "What are Chrome DevTools and what are the key panels?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.debugging, ValidTag.enum.performance],
        answers: ["Chrome DevTools is the built-in debugging and profiling toolset in Chrome. The key panels are: Elements for inspecting and modifying the DOM and CSS in real-time; Console for JavaScript errors, logs, and running code; Sources for debugging JavaScript with breakpoints and step-through; Network for analyzing requests, timing, and waterfall charts; Performance for recording and analyzing runtime performance; Application for inspecting storage, service workers, and cache; and Lighthouse for auditing performance, accessibility, and SEO. I use Elements constantly for CSS debugging, Network to identify slow requests, Console for quick debugging, and Performance when investigating slowness. The Coverage panel is also useful for finding unused JavaScript and CSS. DevTools is essential for frontend development - I have it open basically all the time."],
    },
    {
        text: "What is the Network panel and how do you use it to debug?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.debugging, ValidTag.enum.performance],
        answers: ["The Network panel shows all network requests with timing, size, and status. The waterfall chart visualizes when requests start and how long they take. I use it to identify slow API calls, large assets, failed requests, and caching issues. You can filter by type, search, and throttle network speed to test on slower connections. Click a request to see headers, payload, response, timing breakdown, and initiator. Common debugging scenarios: check if an API call is happening and what it returns, find which requests are slow or blocking, verify caching headers are correct, identify unnecessary requests, and debug CORS issues. The timing tab shows DNS, connection, waiting, and download times separately. I also use it to ensure resources are being served from CDN and check if compression is enabled."],
    },
    {
        text: "What is Lighthouse and how do you use it?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.performance, ValidTag.enum.lighthouse],
        answers: ["Lighthouse is an automated auditing tool built into Chrome DevTools that analyzes performance, accessibility, best practices, SEO, and PWA compliance. It loads your page and measures metrics like First Contentful Paint, Largest Contentful Paint, Time to Interactive, and Cumulative Layout Shift. Each category gets a score 0-100 with specific recommendations. I use it to identify performance bottlenecks, accessibility issues, and SEO problems. Run it in incognito mode to avoid extension interference. The performance score focuses on Core Web Vitals which affect SEO rankings. Common issues it catches include unoptimized images, render-blocking resources, poor contrast ratios, and missing alt text. I run Lighthouse regularly during development and aim for scores above 90, though I prioritize the specific recommendations over the score itself."],
    },
    {
        text: "What is tree shaking and how does it work?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.performance, ValidTag.enum["tree-shaking"]],
        answers: ["Tree shaking is the process of eliminating dead code from your JavaScript bundle. Modern bundlers like Webpack and Rollup analyze ES module imports to determine what code is actually used and remove what isn't. It only works with ES modules because their static structure allows the bundler to determine dependencies at build time. For example, if you import one function from lodash-es, tree shaking ensures you only bundle that function, not the entire library. For it to work effectively, your dependencies need to use ES modules and your code must use import/export syntax. Side effects can prevent tree shaking - you can specify sideEffects in package.json to help the bundler. I make sure to import only what I need and use libraries that support tree shaking for smaller bundle sizes."],
    },
    {
        text: "What is code splitting and how do you implement it?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.performance, ValidTag.enum["code-splitting"]],
        answers: ["Code splitting divides your bundle into smaller chunks that can be loaded on demand, reducing initial load time. In React, you implement it with dynamic imports and React.lazy. Instead of a regular import, you use React.lazy with a dynamic import function, then wrap the component in a Suspense boundary that shows a fallback while loading. Modern bundlers automatically split these into separate chunks. You can split at route level so each page loads its own code, or split large dependencies like charting libraries. Next.js does route-based splitting automatically. The benefit is faster initial page loads since users only download code for what they're viewing. I use it for routes, large dependencies, and below-the-fold content. The tradeoff is managing loading states and potentially more network requests."],
    },
    {
        text: "What is lazy loading and when should you use it?",
        level: Level.enum.mid,
        category: Category.enum.frontend,
        tags: [ValidTag.enum.performance, ValidTag.enum["lazy-loading"]],
        answers: ["Lazy loading defers loading resources until they're actually needed, typically when they're about to enter the viewport. For images, you can use the native loading='lazy' attribute on img tags, or intersection observer for more control. For JavaScript, you use code splitting with dynamic imports. For components, React.lazy loads them on demand. Use lazy loading for below-the-fold images, off-screen content, modal content, tabs, and route components. It dramatically improves initial page load by reducing the amount of data downloaded upfront. The downside is potential layout shift if you don't reserve space, and slight delay when content loads. I lazy load images by default, especially on content-heavy pages. For critical above-the-fold content, load it eagerly. The key is balancing initial performance with user experience."],
    },
];
